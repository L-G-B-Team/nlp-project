{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110156c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le basics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from time import strftime\n",
    "\n",
    "# le mon creation\n",
    "import env\n",
    "import acquire as a\n",
    "import prepare \n",
    "import explore as e\n",
    "import model as m\n",
    "from pprint import pprint\n",
    "\n",
    "# for text digestion\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# nltk: natural language toolkit -> tokenization, stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# what's cookin', good lookin'?\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cbcfa",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114271bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acquire = a.acquire_readmes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10870af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_acquire.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadbabad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/terminal</td>\n",
       "      <td>C++</td>\n",
       "      <td>![terminal-logos](https://user-images.githubus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/PowerToys</td>\n",
       "      <td>C#</td>\n",
       "      <td># Microsoft PowerToys\\n\\n![Hero image for Micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>huggingface/transformers</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;!---\\nCopyright 2020 The HuggingFace Team. Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rust-lang/rust</td>\n",
       "      <td>Rust</td>\n",
       "      <td># The Rust Programming Language\\n\\nThis is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mtdvio/every-programmer-should-know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt; *[Join our community](https://metadevelopmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  repo language  \\\n",
       "0                   microsoft/terminal      C++   \n",
       "1                  microsoft/PowerToys       C#   \n",
       "2             huggingface/transformers   Python   \n",
       "3                       rust-lang/rust     Rust   \n",
       "4  mtdvio/every-programmer-should-know      NaN   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  ![terminal-logos](https://user-images.githubus...  \n",
       "1  # Microsoft PowerToys\\n\\n![Hero image for Micr...  \n",
       "2  <!---\\nCopyright 2020 The HuggingFace Team. Al...  \n",
       "3  # The Rust Programming Language\\n\\nThis is the...  \n",
       "4  > *[Join our community](https://metadevelopmen...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7a5573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f948dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 683 entries, 0 to 682\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             683 non-null    object\n",
      " 1   language         619 non-null    object\n",
      " 2   readme_contents  681 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf82a9",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ccc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepare = prepare.prep_df_for_nlp(df, 'readme_contents', extra_words = prepare.EXTRA_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60976050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prepare.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae07aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d1d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(df, 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3899fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>username</th>\n",
       "      <th>lemmatized_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>awesome actions</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;br&gt;\\n    &lt;img src=\"awes...</td>\n",
       "      <td>awesome actions awesome github actions status ...</td>\n",
       "      <td>awesom action awesom github action statu sdra ...</td>\n",
       "      <td>awesome action awesome github action status sd...</td>\n",
       "      <td>sdras</td>\n",
       "      <td>17532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>InstaPy</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://i.imgu...</td>\n",
       "      <td>instapy tooling automates social media interac...</td>\n",
       "      <td>instapi tool autom social media interact farm ...</td>\n",
       "      <td>instapy tooling automates social medium intera...</td>\n",
       "      <td>InstaPy</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>osquery</td>\n",
       "      <td>Other</td>\n",
       "      <td># osquery\\n\\n&lt;p align=\"center\"&gt;\\n&lt;img alt=\"osq...</td>\n",
       "      <td>osquery altosquery logo width200 src osquery s...</td>\n",
       "      <td>osqueri altosqueri logo width200 src osqueri s...</td>\n",
       "      <td>osquery altosquery logo width200 src osquery s...</td>\n",
       "      <td>osquery</td>\n",
       "      <td>3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Best App</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>\\nBest App\\n----\\n\\n*经常会有朋友想知道有哪些 Apps 或 服务 是值...</td>\n",
       "      <td>best app apps bestapp ios app app starpull req...</td>\n",
       "      <td>best app app bestapp io app app starpul reques...</td>\n",
       "      <td>best app apps bestapp io app app starpull requ...</td>\n",
       "      <td>hzlzh</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>actix web</td>\n",
       "      <td>Other</td>\n",
       "      <td>actix-web/README.md</td>\n",
       "      <td>actixweb readmemd</td>\n",
       "      <td>actixweb readmemd</td>\n",
       "      <td>actixweb readmemd</td>\n",
       "      <td>actix</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sly</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># [Sly](http://darsa.in/sly)\\n\\nJavaScript lib...</td>\n",
       "      <td>sly javascript library onedirectional scrollin...</td>\n",
       "      <td>sli javascript librari onedirect scroll item b...</td>\n",
       "      <td>sly javascript library onedirectional scrollin...</td>\n",
       "      <td>darsain</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>free</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>更新时间 2023-01-12 00:00  \\n所有免费节点都爬取自网络，请勿用于非法用途...</td>\n",
       "      <td>20230112 0000 android windows v2ray v2rayng v2...</td>\n",
       "      <td>20230112 0000 android window v2ray v2rayng v2r...</td>\n",
       "      <td>20230112 0000 android window v2ray v2rayng v2r...</td>\n",
       "      <td>freefq</td>\n",
       "      <td>13112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>hello algorithm</td>\n",
       "      <td>Java</td>\n",
       "      <td>## 简介\\n\\nEnglish version repo and Gitbook is o...</td>\n",
       "      <td>english repo gitbook english branch part1 part...</td>\n",
       "      <td>english repo gitbook english branch part1 part...</td>\n",
       "      <td>english repo gitbook english branch part1 part...</td>\n",
       "      <td>geekxh</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>jq</td>\n",
       "      <td>Other</td>\n",
       "      <td>README.md</td>\n",
       "      <td>readmemd</td>\n",
       "      <td>readmemd</td>\n",
       "      <td>readmemd</td>\n",
       "      <td>stedolan</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Dev For Beginners</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>[![GitHub license](https://img.shields.io/gith...</td>\n",
       "      <td>github license github contributors github issu...</td>\n",
       "      <td>github licens github contributor github issu g...</td>\n",
       "      <td>github license github contributor github issue...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>4654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo    language  \\\n",
       "482        awesome actions  Not Listed   \n",
       "646                InstaPy      Python   \n",
       "474                osquery       Other   \n",
       "545               Best App  Not Listed   \n",
       "539              actix web       Other   \n",
       "..                     ...         ...   \n",
       "47                     sly  JavaScript   \n",
       "268                   free  Not Listed   \n",
       "230        hello algorithm        Java   \n",
       "304                     jq       Other   \n",
       "8    Web Dev For Beginners  JavaScript   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "482  <p align=\"center\">\\n  <br>\\n    <img src=\"awes...   \n",
       "646  <p align=\"center\">\\n  <img src=\"https://i.imgu...   \n",
       "474  # osquery\\n\\n<p align=\"center\">\\n<img alt=\"osq...   \n",
       "545  \\nBest App\\n----\\n\\n*经常会有朋友想知道有哪些 Apps 或 服务 是值...   \n",
       "539                                actix-web/README.md   \n",
       "..                                                 ...   \n",
       "47   # [Sly](http://darsa.in/sly)\\n\\nJavaScript lib...   \n",
       "268  更新时间 2023-01-12 00:00  \\n所有免费节点都爬取自网络，请勿用于非法用途...   \n",
       "230  ## 简介\\n\\nEnglish version repo and Gitbook is o...   \n",
       "304                                          README.md   \n",
       "8    [![GitHub license](https://img.shields.io/gith...   \n",
       "\n",
       "                                                 clean  \\\n",
       "482  awesome actions awesome github actions status ...   \n",
       "646  instapy tooling automates social media interac...   \n",
       "474  osquery altosquery logo width200 src osquery s...   \n",
       "545  best app apps bestapp ios app app starpull req...   \n",
       "539                                  actixweb readmemd   \n",
       "..                                                 ...   \n",
       "47   sly javascript library onedirectional scrollin...   \n",
       "268  20230112 0000 android windows v2ray v2rayng v2...   \n",
       "230  english repo gitbook english branch part1 part...   \n",
       "304                                           readmemd   \n",
       "8    github license github contributors github issu...   \n",
       "\n",
       "                                                  stem  \\\n",
       "482  awesom action awesom github action statu sdra ...   \n",
       "646  instapi tool autom social media interact farm ...   \n",
       "474  osqueri altosqueri logo width200 src osqueri s...   \n",
       "545  best app app bestapp io app app starpul reques...   \n",
       "539                                  actixweb readmemd   \n",
       "..                                                 ...   \n",
       "47   sli javascript librari onedirect scroll item b...   \n",
       "268  20230112 0000 android window v2ray v2rayng v2r...   \n",
       "230  english repo gitbook english branch part1 part...   \n",
       "304                                           readmemd   \n",
       "8    github licens github contributor github issu g...   \n",
       "\n",
       "                                            lemmatized   username  \\\n",
       "482  awesome action awesome github action status sd...      sdras   \n",
       "646  instapy tooling automates social medium intera...    InstaPy   \n",
       "474  osquery altosquery logo width200 src osquery s...    osquery   \n",
       "545  best app apps bestapp io app app starpull requ...      hzlzh   \n",
       "539                                  actixweb readmemd      actix   \n",
       "..                                                 ...        ...   \n",
       "47   sly javascript library onedirectional scrollin...    darsain   \n",
       "268  20230112 0000 android window v2ray v2rayng v2r...     freefq   \n",
       "230  english repo gitbook english branch part1 part...     geekxh   \n",
       "304                                           readmemd   stedolan   \n",
       "8    github license github contributor github issue...  microsoft   \n",
       "\n",
       "     lemmatized_len  \n",
       "482           17532  \n",
       "646             872  \n",
       "474            3064  \n",
       "545            3646  \n",
       "539              17  \n",
       "..              ...  \n",
       "47             1238  \n",
       "268           13112  \n",
       "230             659  \n",
       "304               8  \n",
       "8              4654  \n",
       "\n",
       "[443 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aefc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_word_counts(df):\n",
    "    '''This function generates a dataframe of the \n",
    "    top ten most used words that appear in titles'''\n",
    "    \n",
    "    # creating a df for each language category\n",
    "    go, \n",
    "    java, \n",
    "    javascript, \n",
    "    not_listed, \n",
    "    other, \n",
    "    python, \n",
    "    typescript = e.split_by_language(df)\n",
    "    \n",
    "    #using lang category dfs to generate word frequency for each\n",
    "    javascript_words_freq = e.get_ngram_frequency(javascript.repo)\n",
    "    python_words_freq = e.get_ngram_frequency(python.repo)\n",
    "    typescript_words_freq = e.get_ngram_frequency(typescript.repo)\n",
    "    go_words_freq = e.get_ngram_frequency(go.repo)\n",
    "    other_series_freq = e.get_ngram_frequency(other.repo)\n",
    "    not_listed_freq = e.get_ngram_frequency(not_listed.repo)\n",
    "    java_words_freq = e.get_ngram_frequency(java.repo)\n",
    "    all_words_freq = e.get_ngram_frequency(df.repo)\n",
    "    \n",
    "    # creating a single df of all the langugaes counted words and ordering by 'all'\n",
    "    word_counts = (pd.concat([all_words_freq, javascript_words_freq,typescript_words_freq,go_words_freq, python_words_freq, java_words_freq, other_series_freq, not_listed_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'javascript','typescript','go', 'python', 'java','other','not_listed'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "    \n",
    "    # returning only the top ten most frequent words\n",
    "    return word_counts.sort_values(by = 'all', ascending = False).head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef62354",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtop_word_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtop_word_counts\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m'''This function generates a dataframe of the \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mtop ten most used words that appear in titles'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# creating a df for each language category\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgo\u001b[49m, \n\u001b[1;32m      7\u001b[0m java, \n\u001b[1;32m      8\u001b[0m javascript, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'go' is not defined"
     ]
    }
   ],
   "source": [
    "top_word_counts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5001b",
   "metadata": {},
   "source": [
    "# Explore based on Ryan's notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790827c",
   "metadata": {},
   "source": [
    "# Top five languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9bde3f",
   "metadata": {},
   "source": [
    "### make the following cell Code to generate language series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f8512",
   "metadata": {},
   "source": [
    "JavaScript_words_series = (' '.join(df[df.language == 'JavaScript']['readme_contents']))\n",
    "Python_words_series = (' '.join(df[df.language == 'Python']['readme_contents']))\n",
    "TypeScript_words_series = (' '.join(df[df.language == 'TypeScript']['readme_contents']))\n",
    "Go_words_words_series = (' '.join(df[df.language == 'Go']['readme_contents']))\n",
    "Java_words_series = (' '.join(df[df.language == 'Java']['readme_contents']))\n",
    "\n",
    "all_words_series = (' '.join(df['readme_contents']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0788216",
   "metadata": {},
   "source": [
    "# Thursday: Freqency of a word within a single readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffaa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan have loop run through the contenct of every read me and count the words that are in that readme. \n",
    "# ham_words = clean(' '.join(df[df.label == 'ham']['text']))\n",
    "# readme_words = join ['lemmatized'] but df.label = row\n",
    "df.head()\n",
    "## let's get some sights on word frequency by taking our words back apart\n",
    "# we will split each set of words by the spaces,\n",
    "# turn that into a list, cast that list as a Series,\n",
    "# and then take the value counts of that Series\n",
    "# We will do this for each type of word present\n",
    "#ham_freq = pd.Series(ham_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lemmatized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b98ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in df.lemmatized[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.lemmatized.str.split().apply(lambda x: Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ba8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5959c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_counter(df):\n",
    "    df.lemmatized.str.split().apply(lambda x: Counter(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = e.get_ngram_frequency(df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7fb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = list(ones[ones >10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bed65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BEWARE THIS BOX IS REALLY LONG!!!!!\n",
    "\n",
    "#for word in freq_words:\n",
    "    #print(f'{word}\\n----------------\\n{df[df.lemmatized.str.contains(word)].index.value_counts()}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03590684",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db68f2",
   "metadata": {},
   "source": [
    "#### beginning of block i want in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a86e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe540b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = df.lemmatized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f68209",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1_series = pd.Series(row1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1881b",
   "metadata": {},
   "source": [
    "#### end of block i want in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b838d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.top_five_words(row1_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e591759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to make a loop that runs through the rows of and converts the str of the lemmatized column into series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.top_five_words(df.lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5149696",
   "metadata": {},
   "source": [
    "# looking into significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c11be",
   "metadata": {},
   "source": [
    "## Moving into testing frequency per readme with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = df.lemmatized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "\n",
    "# From the Series we can extract the value_counts, which is our raw count\n",
    "# for term frequency. Once we have the raw counts, we can calculate the\n",
    "# other measures.\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = df.lemmatized[1]\n",
    "row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcab9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(row1.split())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3493ad4",
   "metadata": {},
   "source": [
    "# WORK FOR REPO TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1326728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there significant indication of language in the title alone?\n",
    "# titles will initally be lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86398840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20799c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_name = prepare.tokenize('repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e454dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_title'] = df['repo'].apply(prepare.squeaky_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49885e",
   "metadata": {},
   "source": [
    "## column for lemmatized repo names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ffb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d330ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_title'] = df['repo'].apply(prepare.squeaky_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97341ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dirty_title'] = df['repo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_title_count = df.groupby(['language'])['clean_title'].count()\n",
    "df_clean_title_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b9372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean_title_count = df.groupby(['language', 'clean_title'])['clean_title'].count()\n",
    "df_clean_title_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty_title_count = df.groupby(['language','dirty_title'])['dirty_title'].count()\n",
    "df_dirty_title_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea203b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clean_title.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5510aad",
   "metadata": {},
   "source": [
    "### trying to clean digits out of list of strings that is the clean titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cb2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.clean_title = df['clean_title'].str.replace('\\d+', '')\n",
    "df.clean_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79728709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a033165",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_words = prepare.basic_clean(' '.join(df[df.language == 'Other']['clean_title']))\n",
    "java_script_words = prepare.basic_clean(' '.join(df[df.language == 'JavaScript']['clean_title']))\n",
    "python_words = prepare.basic_clean(' '.join(df[df.language == 'Python']['clean_title']))\n",
    "not_listed_words = prepare.basic_clean(' '.join(df[df.language == 'NotListed']['clean_title']))\n",
    "type_script_words = prepare.basic_clean(' '.join(df[df.language == 'TypeScript']['clean_title']))\n",
    "go_words = prepare.basic_clean(' '.join(df[df.language == 'Go']['clean_title']))\n",
    "java_words = prepare.basic_clean(' '.join(df[df.language == 'Java']['clean_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_freq = pd.Series(other_words).value_counts()\n",
    "java_script_freq = pd.Series(java_script_words).value_counts()\n",
    "python_freq = pd.Series(python_words).value_counts()\n",
    "not_listed_freq = pd.Series(not_listed_words).value_counts()\n",
    "type_script_freq = pd.Series(type_script_words).value_counts()\n",
    "go_freq = pd.Series(go_words).value_counts()\n",
    "java_freq = pd.Series(java_words).value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fe6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.concat([other_freq, java_script_freq, python_freq,not_listed_freq,type_script_freq, go_freq, java_freq], axis=1\n",
    "         ).fillna(0).astype(int)\n",
    "word_counts.columns = ['other','java_script','python', 'not_listed', 'type_script', 'go', 'java']\n",
    "\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all hyphens with a space to separate words\n",
    "df.repo = df.repo.apply(lambda s: s.replace('-', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into a df per language category\n",
    "go, java, javascript, not_listed, other, python, typescript = e.split_by_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_ngram_frequency(df.repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13780821",
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_words_freq = e.get_ngram_frequency(javascript.repo)\n",
    "python_words_freq = e.get_ngram_frequency(python.repo)\n",
    "typescript_words_freq = e.get_ngram_frequency(typescript.repo)\n",
    "go_words_freq = e.get_ngram_frequency(go.repo)\n",
    "other_series_freq = e.get_ngram_frequency(other.repo)\n",
    "not_listed_freq = e.get_ngram_frequency(not_listed.repo)\n",
    "java_words_freq = e.get_ngram_frequency(java.repo)\n",
    "all_words_freq = e.get_ngram_frequency(df.repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_word_counts(df)\n",
    "    '''This function generates a dataframe of the \n",
    "    top ten most used words that appear in titles'''\n",
    "    \n",
    "    # creating a df for each language category\n",
    "    go, \n",
    "    java, \n",
    "    javascript, \n",
    "    not_listed, \n",
    "    other, \n",
    "    python, \n",
    "    typescript = split_by_language(df)\n",
    "    \n",
    "    #using lang category dfs to generate word frequency for each\n",
    "    javascript_words_freq = e.get_ngram_frequency(javascript.repo)\n",
    "    python_words_freq = e.get_ngram_frequency(python.repo)\n",
    "    typescript_words_freq = e.get_ngram_frequency(typescript.repo)\n",
    "    go_words_freq = e.get_ngram_frequency(go.repo)\n",
    "    other_series_freq = e.get_ngram_frequency(other.repo)\n",
    "    not_listed_freq = e.get_ngram_frequency(not_listed.repo)\n",
    "    java_words_freq = e.get_ngram_frequency(java.repo)\n",
    "    all_words_freq = e.get_ngram_frequency(df.repo)\n",
    "    \n",
    "    # creating a single df of all the langugaes counted words and ordering by 'all'\n",
    "    word_counts = (pd.concat([all_words_freq, javascript_words_freq,typescript_words_freq,go_words_freq, python_words_freq, java_words_freq, other_series_freq, not_listed_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'javascript','typescript','go', 'python', 'java','other','not_listed'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "    \n",
    "    # returning only the top ten most frequent words\n",
    "    return word_counts.sort_values(by = 'all', ascending = False).head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "word_counts.sort_values(by='all', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d539daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWC = word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2413f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(e.get_ngram_frequency(go.repo)>1).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_word():\n",
    "    '''This function requires no input because all values are hard coded\n",
    "    based on code run on cleaned, lemmatized, and hyphen-split data\n",
    "    in repo column of train df'''\n",
    "    \n",
    "    df = pd.DataFrame({'language': ['all', 'javascript','typescript','go', 'python', 'java','other','not_listed'],\n",
    "                            'count_pre_split': [443, 94, 40, 38, 46, 37, 147, 41],\n",
    "                            'count_post_split': [567, 127, 55, 44, 67, 52, 207, 69],\n",
    "                            'difference': [24,33,15,6,21,15,60,28],\n",
    "                            'repeats': [53, 3, 4, 1, 2, 4, 12, 3]})\n",
    "    return df\n",
    "title_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unlisted = df.language == 'Not Listed'\n",
    "awesome_unlisted = df.repo.str.contains('awesome')\n",
    "ctab = pd.crosstab(all_unlisted, awesome_unlisted)\n",
    "stat, p, degf, expected = stats.chi2_contingency(ctab)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9432de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unlisted = df.language\n",
    "awesome_unlisted = df.repo.str.contains('react')\n",
    "ctab = pd.crosstab(all_unlisted, awesome_unlisted)\n",
    "stat, p, degf, expected = stats.chi2_contingency(ctab)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975dc12",
   "metadata": {},
   "source": [
    "### words of significance: 'react', 'awesome', 'go'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875f1c8",
   "metadata": {},
   "source": [
    "### Viz for repo titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52493d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_language_per_word():\n",
    "    df = pd.DataFrame({'word': ['React', 'Awesome', 'Go'],\n",
    "                            'Other': [7, 14, 33],\n",
    "                            'Go': [0, 0, 67],\n",
    "                            'JavaScript': [50, 7, 0],\n",
    "                            'TypeScript': [43, 0, 0],\n",
    "                            'NotListed': [0, 79, 0]})\n",
    "    df.plot(\n",
    "    x = 'word',\n",
    "    kind = 'barh',\n",
    "    stacked = True,\n",
    "    title = 'Stacked Bar Graph',\n",
    "    mark_right = True)\n",
    "\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_language_per_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baeb911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08509d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acquire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a454a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_prepare.language == 'Java').value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487af015",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_distribution = pd.DataFrame((df_prepare.language).value_counts(normalize=True))\n",
    "language_distribution = (language_distribution*100).round(1)\n",
    "language_distribution = pd.DataFrame(language_distribution.language.astype(str) + '%')\n",
    "language_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c97d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acquire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1771c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acquire.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646034ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target: str, test_size: float = 0.15):\n",
    "    '''\n",
    "    Takes in a data frame and the train size\n",
    "    It returns train, validate , and test data frames\n",
    "    with validate being 0.05 bigger than test and train has the rest of the data.\n",
    "    '''\n",
    "    train, test = train_test_split(\n",
    "        df, stratify=df[target], test_size=test_size, random_state=27)\n",
    "    train, validate = train_test_split(train,  stratify=train[target],\n",
    "                                       test_size=(\n",
    "        test_size + 0.05)/(1-test_size), random_state=27)\n",
    "\n",
    "    return train, validate, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(df, 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target: str, test_size: float = 0.15):\n",
    "    '''\n",
    "    Takes in a data frame and the train size\n",
    "    It returns train, validate , and test data frames\n",
    "    with validate being 0.05 bigger than test and train has the rest of the data.\n",
    "    '''\n",
    "    train, test = train_test_split(\n",
    "        df, stratify=df[target], test_size=test_size, random_state=27)\n",
    "    train, validate = train_test_split(train,  stratify=train[target],\n",
    "                                       test_size=(\n",
    "        test_size + 0.05)/(1-test_size), random_state=27)\n",
    "\n",
    "    return train, validate, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab3ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y,test_x,test_y = m.get_features_and_target(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80344c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg, rf, dt = m.create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7aa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model_and_evaluate(train_x, train_y, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed077ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25059d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_significant_words_in_title(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f103f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
